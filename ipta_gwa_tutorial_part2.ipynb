{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using enterprise to analyze PTA data\n",
    "\n",
    "In this notebook you will learn:\n",
    "* How to use `enterprise` to interact with IPTA data,\n",
    "* How to setup an analysis of indiviudual pulsar noise properties,\n",
    "* How to search in PTA data for GWs,\n",
    "* How to perform Bayesian model selection,\n",
    "* How to post-process your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T16:11:20.468597Z",
     "start_time": "2018-05-11T16:11:20.454565Z"
    }
   },
   "source": [
    "# Pre-requisites (installation etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Install `miniconda` locally**\n",
    "\n",
    "    `wget -q https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh`\n",
    "    \n",
    "    `bash Miniconda2-latest-Linux-x86_64.sh -b -p ~/.local/opt/miniconda2`\n",
    "    \n",
    "    `rm Miniconda2-latest-Linux-x86_64.sh`\n",
    "\n",
    "\n",
    "- **Add minicondaâ€™s `python`  to the front of your `$PATH`**\n",
    "\n",
    "    `echo \"export PATH=$HOME/.local/opt/miniconda2/bin:$PATH\" >> .bashrc`\n",
    "    \n",
    "    `source .bashrc`\n",
    "\n",
    "\n",
    "- **Install the basic python packages**\n",
    "\n",
    "    `conda install -y numpy==1.13.3 cython scipy`\n",
    "\n",
    "\n",
    "- **Install latest `libstempo` from GitHub with `pip`.  `tempo2` should be installed automatically.  Add extra ephemerides if needed**\n",
    "\n",
    "    `pip install git+https://github.com/vallis/libstempo@master`\n",
    "\n",
    "\n",
    "- **Install more python packages**\n",
    "\n",
    "    `conda install -y matplotlib ipython h5py mpi4py numexpr statsmodels astropy ephem`\n",
    "\n",
    "\n",
    "- **Install non-conda packages with `pip`**\n",
    "\n",
    "    `pip install healpy acor line_profiler jplephem corner numdifftools`\n",
    "\n",
    "\n",
    "- [optional] **Install `scikit-sparse`**\n",
    "\n",
    "    `conda install -c menpo scikit-sparse`\n",
    "   \n",
    "   \n",
    "- [optional] **Alternatively install `suite sparse` and then use pip to install `scikit-sparse` (maybe needed with python 3.6)**\n",
    "\n",
    "    `conda install -c conda-forge suitesparse`\n",
    "    \n",
    "    `pip install git+https://github.com/scikit-sparse/scikit-sparse.git@master`\n",
    "\n",
    "\n",
    "- **Install PTMCMC for sampling**\n",
    "\n",
    "    `pip install git+https://github.com/jellis18/PTMCMCSampler@master`\n",
    "\n",
    "\n",
    "- **Finally, install enterprise**\n",
    "\n",
    "    `pip install git+https://github.com/nanograv/enterprise@master`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:39.150382Z",
     "start_time": "2018-05-15T21:48:39.094542Z"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os, glob, json \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as sl\n",
    "\n",
    "import enterprise\n",
    "from enterprise.pulsar import Pulsar\n",
    "import enterprise.signals.parameter as parameter\n",
    "from enterprise.signals import utils\n",
    "from enterprise.signals import signal_base\n",
    "from enterprise.signals import selections\n",
    "from enterprise.signals.selections import Selection\n",
    "from enterprise.signals import white_signals\n",
    "from enterprise.signals import gp_signals\n",
    "from enterprise.signals import deterministic_signals\n",
    "import enterprise.constants as const\n",
    "\n",
    "import corner\n",
    "from PTMCMCSampler.PTMCMCSampler import PTSampler as ptmcmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a python dictionary of pulsar names and PTAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:40.498208Z",
     "start_time": "2018-05-15T21:48:40.378625Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The pulsars we'll be analyzing\n",
    "psrdict = {'J1713+0747': [{'pta': ['NANOGrav', 'PPTA']}], \n",
    "           'J1909-3744': [{'pta': ['NANOGrav', 'PPTA']}], \n",
    "           'J1640+2224': [{'pta': ['NANOGrav']}], \n",
    "           'J1600-3053': [{'pta': ['NANOGrav']}],\n",
    "           'J2317+1439': [{'pta': ['NANOGrav']}], \n",
    "           'J1918-0642': [{'pta': ['NANOGrav']}], \n",
    "           'J1614-2230': [{'pta': ['NANOGrav']}], \n",
    "           'J1744-1134': [{'pta': ['NANOGrav', 'PPTA']}],\n",
    "           'J0030+0451': [{'pta': ['NANOGrav']}], \n",
    "           'J2145-0750': [{'pta': ['NANOGrav']}], \n",
    "           'J1857+0943': [{'pta': ['NANOGrav']}], \n",
    "           'J1853+1303': [{'pta': ['NANOGrav']}], \n",
    "           'J0613-0200': [{'pta': ['NANOGrav']}],\n",
    "           'J1455-3330': [{'pta': ['NANOGrav']}], \n",
    "           'J1741+1351': [{'pta': ['NANOGrav']}], \n",
    "           'J2010-1323': [{'pta': ['NANOGrav']}], \n",
    "           'J1024-0719': [{'pta': ['NANOGrav']}], \n",
    "           'J1012+5307': [{'pta': ['NANOGrav']}],\n",
    "           'J0437-4715': [{'pta': ['PPTA']}]\n",
    "          }\n",
    "psrlist=psrdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:41.136823Z",
     "start_time": "2018-05-15T21:48:41.106007Z"
    }
   },
   "outputs": [],
   "source": [
    "psrlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get par, tim, and noise files\n",
    "Here we collect the tim and par files as well as noise files made from the `PAL2` code. These are the same par, tim, and noise files used in the 9-year analysis papers. We use the convienience function above to convert from `PAL2` noise files to `enterprise` parameter dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:42.658570Z",
     "start_time": "2018-05-15T21:48:42.631742Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = './partim_filtered_ppta_ng/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:43.043752Z",
     "start_time": "2018-05-15T21:48:43.007076Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parfiles = sorted(glob.glob(datadir + '/*.par'))\n",
    "timfiles = sorted(glob.glob(datadir + '/*.tim'))\n",
    "\n",
    "# filter\n",
    "parfiles = [x for x in parfiles if x.split('/')[-1].split('.')[0] in psrlist]\n",
    "timfiles = [x for x in timfiles if x.split('/')[-1].split('.')[0] in psrlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:43.452613Z",
     "start_time": "2018-05-15T21:48:43.421953Z"
    }
   },
   "outputs": [],
   "source": [
    "len(parfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into Pulsar class list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `enterprise` Pulsar class uses `libstempo` to read in `par` and `tim` files, then stores all pulsar data into a `Pulsar` object. This object contains all data and meta-data needed for the ensuing pulsar and PTA analysis. You no longer to reference the `par` and `tim` files after this cell.\n",
    "* Note below that you can explicitly declare which version of the JPL solar-system ephemeris model that will be used to compute the Roemer delay between the geocenter and the barycenter (e.g. `DE436`). Otherwise the default values will be taken from the `par` files. Explicitly declaring the version here is good practice.\n",
    "* You can also explicitly set the clock file to a version of `BIPM`, e.g. `BIPM(2015)`. This is less important, and you can let the code take the value from the `par` file.\n",
    "* When you execute the following cell, you will get warnings like `WARNING: Could not find pulsar distance for PSR ...`. Don't worry! This is expected, and fine. Not all pulsars have well constrained distances, and will be set to `1 kpc` with a `20%` uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:00.790991Z",
     "start_time": "2018-05-15T21:48:53.703630Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psrs = []\n",
    "for p, t in zip(parfiles[:2], timfiles[:2]):\n",
    "    psr = Pulsar(p, t, ephem='DE436', clk=None)\n",
    "    psrs.append(psr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTA Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can read-in some previously computed noise properties from single-pulsar analyses. These are things like `EFAC`, `EQUAD`, and (for `NANOGrav`) `ECORR`. \n",
    "* In practice, we set these white-noise properties as fixed in the low-frequency noise / GW searches.\n",
    "* The noise properties have been stored as `json` files, and are read in to a big parameter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:00.827936Z",
     "start_time": "2018-05-15T21:49:00.793658Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noisefiles = sorted(glob.glob('./partim_filtered_ppta_ng/noisefiles_ppta_ng_normal/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:00.874553Z",
     "start_time": "2018-05-15T21:49:00.830786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "for nf in noisefiles:\n",
    "    with open(nf, 'r') as fin:\n",
    "        params.update(json.load(fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up `enterprise` model for PTA upper-limit (*verbose version*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usually, in a full PTA analysis we fix all of the white noise (EFAC, EQUAD, and ECORR) parameters to the values obtained from the noise files. This is done by using `Constant` parameters. In this case we do not specify a default value for all instances of that parameter but instead will set them, based on their initialized pulsar and backend specific name, later via the `set_default_params` method of `PTA`. \n",
    "\n",
    "* We use the `Selection` object to define which noise parameters are assigned to which chunks of TOAs. This selection is based on unique combination of backends and receivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T16:39:50.133639Z",
     "start_time": "2018-05-11T16:39:50.102972Z"
    }
   },
   "source": [
    "* Another feature to notice is that **for upper limits** we do not use a uniform prior on the log of the red-noise or GWB amplitude. Instead we use a `LinearExp` prior (short for linear-exponent prior), that is a prior of the form $p(x)\\propto 10^x$. This is how we can still use the log of the parameter to sample but place a uniform prior on the parameter itself. We do this for both the red noise and GWB amplitude parameters. **For detection analyses** we still use a `Uniform` prior on the log of the red-noise and GWB amplitude. \n",
    "\n",
    "* In order to save on computing time we do not include spatial correlations here. Instead we model the GWB as a common red process across all pulsars. In `enterprise` we can do this with a simple trick. We pre-initialize the parameters before passing them to the `Signal` model. In this way the *same* parameter instance is used for all pulsars. Lastly, we fixt the spectral index of the GWB to be 13/3 (4.33) using the `Constant` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:45.238037Z",
     "start_time": "2018-05-15T21:49:45.209705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the maximum time span to set GW frequency sampling\n",
    "tmin = [p.toas.min() for p in psrs]\n",
    "tmax = [p.toas.max() for p in psrs]\n",
    "Tspan = np.max(tmax) - np.min(tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:48.496954Z",
     "start_time": "2018-05-15T21:49:48.470085Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define selection by observing backend\n",
    "selection = selections.Selection(selections.by_backend)\n",
    "\n",
    "# special selection for ECORR only use wideband NANOGrav data\n",
    "selection2 = selections.Selection(selections.nanograv_backends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:50.042751Z",
     "start_time": "2018-05-15T21:49:50.005677Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# white noise parameters\n",
    "# since we are fixing these to values from the noise file we set\n",
    "# them as constant parameters\n",
    "efac = parameter.Constant()\n",
    "equad = parameter.Constant()\n",
    "ecorr = parameter.Constant()\n",
    "\n",
    "# red noise parameters\n",
    "log10_A = parameter.LinearExp(-20, -11)\n",
    "gamma = parameter.Uniform(0, 7)\n",
    "\n",
    "# dm-variation parameters\n",
    "log10_A_dm = parameter.LinearExp(-20, -11)\n",
    "gamma_dm = parameter.Uniform(0, 7)\n",
    "\n",
    "# GW parameters (initialize with names here to use parameters in common across pulsars)\n",
    "log10_A_gw = parameter.LinearExp(-18,-12)('log10_A_gw')\n",
    "gamma_gw = parameter.Constant(4.33)('gamma_gw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T16:44:44.713491Z",
     "start_time": "2018-05-11T16:44:44.685587Z"
    }
   },
   "source": [
    "### Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:51.557605Z",
     "start_time": "2018-05-15T21:49:51.499006Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# white noise\n",
    "ef = white_signals.MeasurementNoise(efac=efac, selection=selection)\n",
    "eq = white_signals.EquadNoise(log10_equad=equad, selection=selection)\n",
    "ec = white_signals.EcorrKernelNoise(log10_ecorr=ecorr, selection=selection2)\n",
    "\n",
    "# red noise (powerlaw with 30 frequencies)\n",
    "pl = utils.powerlaw(log10_A=log10_A, gamma=gamma)\n",
    "rn = gp_signals.FourierBasisGP(spectrum=pl, components=30, Tspan=Tspan)\n",
    "\n",
    "# DM-variations (powerlaw with 30 frequencies)\n",
    "dm_basis = utils.createfourierdesignmatrix_dm(nmodes=30, Tspan=Tspan)\n",
    "dm_pl = utils.powerlaw(log10_A=log10_A_dm, gamma=gamma_dm)\n",
    "dm_gp = gp_signals.BasisGP(dm_pl, dm_basis, name='dm_gp')\n",
    "\n",
    "# gwb (no spatial correlations)\n",
    "cpl = utils.powerlaw(log10_A=log10_A_gw, gamma=gamma_gw)\n",
    "gw = gp_signals.FourierBasisGP(spectrum=cpl, components=30, Tspan=Tspan, name='gw')\n",
    "\n",
    "# for spatial correltions you can do...\n",
    "#orf = utils.hd_orf()\n",
    "#crn = gp_signals.FourierBasisCommonGP(cpl, orf, components=30, Tspan=Tspan, name='gw')\n",
    "\n",
    "# to add solar system ephemeris modeling...\n",
    "eph = deterministic_signals.PhysicalEphemerisSignal(use_epoch_toas=True)\n",
    "\n",
    "# timing model\n",
    "tm = gp_signals.TimingModel(use_svd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:52.662732Z",
     "start_time": "2018-05-15T21:49:52.638142Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full model\n",
    "s = ef + eq + rn + dm_gp + tm + eph + gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:55.063952Z",
     "start_time": "2018-05-15T21:49:53.602147Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intialize PTA, adding ecorr only for NANOGrav pulsars\n",
    "models = []\n",
    "        \n",
    "for p in psrs:    \n",
    "    if 'NANOGrav' in p.flags['pta']:\n",
    "        s2 = s + ec \n",
    "        models.append(s2(p))\n",
    "    else:\n",
    "        models.append(s(p))\n",
    "    \n",
    "pta = signal_base.PTA(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:56.940424Z",
     "start_time": "2018-05-15T21:49:56.910938Z"
    }
   },
   "outputs": [],
   "source": [
    "pta.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set white noise parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:50:00.319108Z",
     "start_time": "2018-05-15T21:50:00.244934Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pta.set_default_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters drawn from prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:50:03.822379Z",
     "start_time": "2018-05-15T21:50:03.788843Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "ndim = len(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:50:06.902347Z",
     "start_time": "2018-05-15T21:50:06.866018Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial jump covariance matrix\n",
    "cov = np.diag(np.ones(ndim) * 0.01**2)\n",
    "\n",
    "sampler = ptmcmc(ndim, pta.get_lnlikelihood, pta.get_lnprior, cov, \n",
    "                 outDir='./chains/ipta_dr2_ng_ppta_gwb/', resume=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:39.157421Z",
     "start_time": "2018-05-15T21:50:07.962002Z"
    }
   },
   "outputs": [],
   "source": [
    "# sampler for N steps\n",
    "N = int(5e6)\n",
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "sampler.sample(x0, N, SCAMweight=30, AMweight=15, DEweight=50, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:44.119807Z",
     "start_time": "2018-05-15T21:51:44.060350Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = np.loadtxt('./chains/ipta_dr2_ng_ppta_gwb/chain_1.txt')\n",
    "burn = int(0.25 * chain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:46.102261Z",
     "start_time": "2018-05-15T21:51:45.927388Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(chain[burn:,-5], 50, normed=True, histtype='step', lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Upper limit value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:49.718217Z",
     "start_time": "2018-05-15T21:51:49.682886Z"
    }
   },
   "outputs": [],
   "source": [
    "upper = 10**np.percentile(chain[burn:, -5], q=95)\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Add other custom functions to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:54.036922Z",
     "start_time": "2018-05-15T21:51:54.005735Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## we add a new custom function that takes the form of a dispersive (1 / \\nu**2) \n",
    "## exponential dip in the residuals of `J1713+0747` due to a void in the ISM \n",
    "## plasma. This is a real effect that has been observed.\n",
    "\n",
    "@signal_base.function\n",
    "def chrom_exp_decay(toas, freqs, log10_Amp=-7,\n",
    "                    t0=54000, log10_tau=1.7, idx=2):\n",
    "    \"\"\"\n",
    "    Chromatic exponential-dip delay term in TOAs.\n",
    "\n",
    "    :param t0: time of exponential minimum [MJD]\n",
    "    :param tau: 1/e time of exponential [s]\n",
    "    :param log10_Amp: amplitude of dip\n",
    "    :param idx: index of chromatic dependence\n",
    "\n",
    "    :return wf: delay time-series [s]\n",
    "    \"\"\"\n",
    "    t0 *= const.day\n",
    "    tau = 10**log10_tau * const.day\n",
    "    wf = -10**log10_Amp * np.heaviside(toas - t0, 1) * \\\n",
    "        np.exp(- (toas - t0) / tau)\n",
    "\n",
    "    return wf * (1400 / freqs) ** idx\n",
    "\n",
    "def dm_exponential_dip(tmin, tmax, idx=2, name='dmexp'):\n",
    "    \"\"\"\n",
    "    Returns chromatic exponential dip (i.e. TOA advance):\n",
    "\n",
    "    :param tmin, tmax:\n",
    "        search window for exponential dip time.\n",
    "    :param idx:\n",
    "        index of radio frequency dependence (i.e. DM is 2). If this is set\n",
    "        to 'vary' then the index will vary from 1 - 6\n",
    "    :param name: Name of signal\n",
    "\n",
    "    :return dmexp:\n",
    "        chromatic exponential dip waveform.\n",
    "    \"\"\"\n",
    "    t0_dmexp = parameter.Uniform(tmin,tmax)\n",
    "    log10_Amp_dmexp = parameter.Uniform(-10, -2)\n",
    "    log10_tau_dmexp = parameter.Uniform(np.log10(5), np.log10(100))\n",
    "    wf = chrom_exp_decay(log10_Amp=log10_Amp_dmexp, t0=t0_dmexp,\n",
    "                         log10_tau=log10_tau_dmexp, idx=idx)\n",
    "    dmexp = deterministic_signals.Deterministic(wf, name=name)\n",
    "\n",
    "    return dmexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:54.639213Z",
     "start_time": "2018-05-15T21:51:54.608904Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## we add a new custom function that takes the form of a dispersive (1 / \\nu**2) \n",
    "## annual term. This is a real effect that can be observed in NANOGrav DMX values.\n",
    "\n",
    "@signal_base.function\n",
    "def chrom_yearly_sinusoid(toas, freqs, log10_Amp=-7, phase=0, idx=2):\n",
    "    \"\"\"\n",
    "    Chromatic annual sinusoid.\n",
    "\n",
    "    :param log10_Amp: amplitude of sinusoid\n",
    "    :param phase: initial phase of sinusoid\n",
    "    :param idx: index of chromatic dependence\n",
    "\n",
    "    :return wf: delay time-series [s]\n",
    "    \"\"\"\n",
    "\n",
    "    wf = 10**log10_Amp * np.sin( 2 * np.pi * const.fyr * toas + phase)\n",
    "    return wf * (1400 / freqs) ** idx\n",
    "\n",
    "def dm_annual_signal(idx=2, name='dm_s1yr'):\n",
    "    \"\"\"\n",
    "    Returns chromatic annual signal (i.e. TOA advance):\n",
    "\n",
    "    :param idx:\n",
    "        index of radio frequency dependence (i.e. DM is 2). If this is set\n",
    "        to 'vary' then the index will vary from 1 - 6\n",
    "    :param name: Name of signal\n",
    "\n",
    "    :return dm1yr:\n",
    "        chromatic annual waveform.\n",
    "    \"\"\"\n",
    "    log10_Amp_dm1yr = parameter.Uniform(-10, -2)\n",
    "    phase_dm1yr = parameter.Uniform(0, 2*np.pi)\n",
    "\n",
    "    wf = chrom_yearly_sinusoid(log10_Amp=log10_Amp_dm1yr,\n",
    "                               phase=phase_dm1yr, idx=idx)\n",
    "    dm1yr = deterministic_signals.Deterministic(wf, name=name)\n",
    "\n",
    "    return dm1yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:55.950822Z",
     "start_time": "2018-05-15T21:51:55.923794Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full model\n",
    "s = ef + eq + rn + dm_gp + tm + eph + gw\n",
    "\n",
    "# add annual DM term for all pulsars\n",
    "s += dm_annual_signal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:59.807991Z",
     "start_time": "2018-05-15T21:51:58.479419Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a DM exponential dip for J1713+0747\n",
    "models = []\n",
    "\n",
    "for p in psrs:    \n",
    "    if 'NANOGrav' in p.flags['pta']:\n",
    "        s2 = s + ec \n",
    "        if p.name == 'J1713+0747':\n",
    "            s3 = s2 + dm_exponential_dip(tmin=(np.min(tmin)/86400.0), \n",
    "                                         tmax=(np.max(tmax)/86400.0))\n",
    "            models.append(s3(p))\n",
    "        else:\n",
    "            models.append(s2(p))\n",
    "    else:\n",
    "        models.append(s(p))\n",
    "        \n",
    "pta = signal_base.PTA(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:52:01.123368Z",
     "start_time": "2018-05-15T21:52:01.058365Z"
    }
   },
   "outputs": [],
   "source": [
    "pta.set_default_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:52:03.270477Z",
     "start_time": "2018-05-15T21:52:03.239314Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "ndim = len(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:52:03.642156Z",
     "start_time": "2018-05-15T21:52:03.610390Z"
    }
   },
   "outputs": [],
   "source": [
    "pta.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:52:07.810723Z",
     "start_time": "2018-05-15T21:52:07.780634Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial jump covariance matrix\n",
    "cov = np.diag(np.ones(ndim) * 0.01**2)\n",
    "\n",
    "sampler = ptmcmc(ndim, pta.get_lnlikelihood, pta.get_lnprior, cov, \n",
    "                 outDir='./chains/ipta_dr2_ng_ppta_gwb/', resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:53:02.695534Z",
     "start_time": "2018-05-15T21:52:09.212572Z"
    }
   },
   "outputs": [],
   "source": [
    "# sampler for N steps\n",
    "N = int(5e6)\n",
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "sampler.sample(x0, N, SCAMweight=30, AMweight=15, DEweight=50, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, the easy way to do all of this...\n",
    "\n",
    "We use `enterprise_extensions` as in the single-pulsar analysis tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:53:11.676320Z",
     "start_time": "2018-05-15T21:53:11.629096Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enterprise_extensions\n",
    "from enterprise_extensions import models, model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:56:18.738032Z",
     "start_time": "2018-05-15T21:56:17.309346Z"
    }
   },
   "outputs": [],
   "source": [
    "## Note that we all still have work to do! This function can do everything\n",
    "## as the routine above, but will not add the DM exponential dip in J1713+0747.\n",
    "\n",
    "pta = models.model_general(psrs, psd='powerlaw', noisedict=params, components=30, \n",
    "                      gamma_common=4.33, upper_limit=True, bayesephem=True, \n",
    "                      dm_var=True, dm_type='gp', dm_psd='powerlaw', dm_annual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:56:20.663093Z",
     "start_time": "2018-05-15T21:56:20.632086Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup an instance of a HyperModel.\n",
    "# This class currently works with pulsars having unique noise model\n",
    "# descriptions for custom proposal distributoons and jumps.\n",
    "super_model = model_utils.HyperModel({0: pta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:56:20.823333Z",
     "start_time": "2018-05-15T21:56:20.790108Z"
    }
   },
   "outputs": [],
   "source": [
    "outdir = './chains/ipta_dr2_ng_ppta_gwb/'\n",
    "sampler = super_model.setup_sampler(resume=False, outdir=outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:56:21.506309Z",
     "start_time": "2018-05-15T21:56:21.474529Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sampler for N steps\n",
    "N = int(5e6)\n",
    "x0 = super_model.initial_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:58:54.315884Z",
     "start_time": "2018-05-15T21:56:25.820406Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample\n",
    "sampler.sample(x0, N, SCAMweight=30, AMweight=15, DEweight=50, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:58:58.146382Z",
     "start_time": "2018-05-15T21:58:58.013143Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in chains and parameters\n",
    "\n",
    "chain = np.loadtxt(outdir + '/chain_1.txt')\n",
    "burn = int(0.25*chain.shape[0])\n",
    "pars = np.loadtxt(outdir + '/pars.txt', dtype=np.unicode_)\n",
    "\n",
    "pp = model_utils.PostProcessing(chain, pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:58:58.777011Z",
     "start_time": "2018-05-15T21:58:58.555011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot GW amplitude posterior\n",
    "ind = list(pars).index('log10_A_gw')\n",
    "plt.hist(chain[burn:,ind], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:59:00.397744Z",
     "start_time": "2018-05-15T21:59:00.366793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute upper limit\n",
    "print model_utils.ul(chain[burn:, ind], q=95.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTA Model Selection\n",
    "\n",
    "We want to be able to compute the Bayesian odds for a GWB in the data. This can be done using the same model selection scheme as in the single-pulsar noise analysis, where we now choose between a model with a common (but uncorrelated) red process in the pulsars, and a GWB affecting all pulsars.\n",
    "\n",
    "We typically perform detection-type analyses with uniform-in-log priors on all amplitude parameters for low-frequency processes. This is implemented below whenever we switch `upper_limit` to be equal to `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dictionary of PTA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:59:25.363204Z",
     "start_time": "2018-05-15T21:59:22.414521Z"
    }
   },
   "outputs": [],
   "source": [
    "nmodels = 2\n",
    "mod_index = np.arange(nmodels)\n",
    "\n",
    "# Make dictionary of PTAs.\n",
    "pta = dict.fromkeys(mod_index)\n",
    "pta[0] = models.model_general(psrs, psd='powerlaw', noisedict=params, components=30, \n",
    "                      gamma_common=4.33, upper_limit=False, bayesephem=True, \n",
    "                      dm_var=True, dm_type='gp', dm_psd='powerlaw', dm_annual=False)\n",
    "pta[1] = models.model_general(psrs, psd='powerlaw', noisedict=params, orf='hd', components=30, \n",
    "                      gamma_common=4.33, upper_limit=False, bayesephem=True, \n",
    "                      dm_var=True, dm_type='gp', dm_psd='powerlaw', dm_annual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:59:38.043468Z",
     "start_time": "2018-05-15T21:59:38.006027Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_model = model_utils.HyperModel(pta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:59:40.020837Z",
     "start_time": "2018-05-15T21:59:39.985755Z"
    }
   },
   "outputs": [],
   "source": [
    "sampler = super_model.setup_sampler(resume=False, outdir=outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:59:40.335389Z",
     "start_time": "2018-05-15T21:59:40.301829Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sampler for N steps\n",
    "N = int(5e6)\n",
    "x0 = super_model.initial_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T22:07:38.858293Z",
     "start_time": "2018-05-15T21:59:41.689205Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample\n",
    "sampler.sample(x0, N, SCAMweight=30, AMweight=15, DEweight=50, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T22:07:42.274771Z",
     "start_time": "2018-05-15T22:07:41.979583Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chain = np.loadtxt(outdir + '/chain_1.txt')\n",
    "burn = int(0.25*chain.shape[0])\n",
    "pars = np.loadtxt(outdir + '/pars.txt', dtype=np.unicode_)\n",
    "\n",
    "pp = model_utils.PostProcessing(chain, pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T22:07:44.047020Z",
     "start_time": "2018-05-15T22:07:43.807128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot histgram for GW amplitude\n",
    "chain_burn = chain[burn:,:]\n",
    "\n",
    "ind_model = list(pars).index('nmodel')\n",
    "ind_gwamp = list(pars).index('log10_A_gw')\n",
    "\n",
    "# ORF = None\n",
    "#plt.hist(chain_burn[chain_burn[:, ind_model] < 0.5, ind_gwamp], bins=40);\n",
    "\n",
    "# ORF = Hellings & Downs\n",
    "plt.hist(chain_burn[chain_burn[:, ind_model] > 0.5, ind_gwamp], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T22:07:46.481391Z",
     "start_time": "2018-05-15T22:07:46.244859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot histogram for GWB model selection\n",
    "plt.hist(chain_burn[:, ind_model], bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savage-Dickey Bayes factor\n",
    "\n",
    "This gives the signal-vs-noise Bayes factor for a common red process in the pulsars plus intrisnc noise, versus intrinsic noise alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T22:08:38.949894Z",
     "start_time": "2018-05-15T22:08:38.920953Z"
    }
   },
   "outputs": [],
   "source": [
    "print model_utils.bayes_fac(chain_burn[chain_burn[:, ind_model] < 0.5, ind_gwamp], ntol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior odds ratio\n",
    "\n",
    "This gives the Bayesian odds between a model with a Hellings & Downs correlated red process between pulsars, and a common (but uncorrelated) red process between pulsars. This is the smoking-gun detection statsitic for a GWB signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T22:08:40.590729Z",
     "start_time": "2018-05-15T22:08:40.559995Z"
    }
   },
   "outputs": [],
   "source": [
    "print model_utils.odds_ratio(chain_burn[:, ind_model], models=[0,1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "743px",
    "left": "0px",
    "right": "1458px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
